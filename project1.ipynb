{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run proj1_helpers.py\n",
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1. ...  1. -1. -1.]\n",
      "----------------------------------\n",
      "[[ 138.47    51.655   97.827 ...    1.24    -2.475  113.497]\n",
      " [ 160.937   68.768  103.235 ... -999.    -999.      46.226]\n",
      " [-999.     162.172  125.953 ... -999.    -999.      44.251]\n",
      " ...\n",
      " [ 105.457   60.526   75.839 ... -999.    -999.      41.992]\n",
      " [  94.951   19.362   68.812 ... -999.    -999.       0.   ]\n",
      " [-999.      72.756   70.831 ... -999.    -999.       0.   ]]\n",
      "----------------------------------\n",
      "[100000 100001 100002 ... 349997 349998 349999]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print('----------------------------------')\n",
    "print(tX)\n",
    "print('----------------------------------')\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.insert(tX, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.   ,  138.47 ,   51.655, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [   1.   ,  160.937,   68.768, ..., -999.   , -999.   ,   46.226],\n",
       "       [   1.   , -999.   ,  162.172, ..., -999.   , -999.   ,   44.251],\n",
       "       ...,\n",
       "       [   1.   ,  105.457,   60.526, ..., -999.   , -999.   ,   41.992],\n",
       "       [   1.   ,   94.951,   19.362, ..., -999.   , -999.   ,    0.   ],\n",
       "       [   1.   , -999.   ,   72.756, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "There seems to be quiet a few incorrect values \"-999\", for now we'll set these equal to the average of their respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.where(tx==-999, np.nan, tx) # replace -999 value with nan\n",
    "col_mean = np.nanmean(tx, axis=0)\n",
    "inds_nan = np.where(np.isnan(tx))\n",
    "tx[inds_nan] = np.take(col_mean, inds_nan[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. , 138.5,  51.7, ...,   1.2,  -2.5, 113.5],\n",
       "       [  1. , 160.9,  68.8, ...,  -0. ,  -0. ,  46.2],\n",
       "       [  1. , 121.9, 162.2, ...,  -0. ,  -0. ,  44.3],\n",
       "       ...,\n",
       "       [  1. , 105.5,  60.5, ...,  -0. ,  -0. ,  42. ],\n",
       "       [  1. ,  95. ,  19.4, ...,  -0. ,  -0. ,   0. ],\n",
       "       [  1. , 121.9,  72.8, ...,  -0. ,  -0. ,   0. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(tx,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing predictions {-1;1} --> {0;1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.copy(y)\n",
    "y_log = np.where(y_log==-1, 0, y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the min and max values for each columns of tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "minmax = dataset_minmax(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 1.0],\n",
       " [9.044, 1192.026],\n",
       " [0.0, 690.075],\n",
       " [6.329, 1349.351],\n",
       " [0.0, 2834.999],\n",
       " [0.0, 8.503],\n",
       " [13.602, 4974.979],\n",
       " [-18.066, 16.69],\n",
       " [0.208, 5.684],\n",
       " [0.0, 2834.999],\n",
       " [46.104, 1852.462],\n",
       " [0.047, 19.773],\n",
       " [-1.414, 1.414],\n",
       " [0.0, 1.0],\n",
       " [20.0, 764.408],\n",
       " [-2.499, 2.497],\n",
       " [-3.142, 3.142],\n",
       " [26.0, 560.271],\n",
       " [-2.505, 2.503],\n",
       " [-3.142, 3.142],\n",
       " [0.109, 2842.617],\n",
       " [-3.142, 3.142],\n",
       " [13.678, 2003.976],\n",
       " [0.0, 3.0],\n",
       " [30.0, 1120.573],\n",
       " [-4.499, 4.499],\n",
       " [-3.142, 3.141],\n",
       " [30.0, 721.456],\n",
       " [-4.5, 4.5],\n",
       " [-3.142, 3.142],\n",
       " [0.0, 1633.433]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_normalized = np.copy(tx)\n",
    "normalize_dataset(tx_normalized, minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.10940657 0.07485418 ... 0.63777778 0.10614258 0.06948372]\n",
      " [1.         0.1283984  0.09965294 ... 0.49868386 0.4997482  0.02829991]\n",
      " [1.         0.09536454 0.23500634 ... 0.49868386 0.4997482  0.0270908 ]\n",
      " ...\n",
      " [1.         0.08149997 0.08770931 ... 0.49868386 0.4997482  0.02570782]\n",
      " [1.         0.07261903 0.02805782 ... 0.49868386 0.4997482  0.        ]\n",
      " [1.         0.09536454 0.10543202 ... 0.49868386 0.4997482  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tx_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardized dataset (works well if features are distributed according to a gaussian curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_standardized = np.copy(tx)\n",
    "means = column_means(tx_standardized)\n",
    "stdevs = column_stdevs(tx_standardized, means)\n",
    "standardize_dataset(tx_standardized, means, stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  3.14910026e-01  6.83318303e-02 ...  1.14381645e+00\n",
      "  -2.52713783e+00  4.12509672e-01]\n",
      " [ 1.00000000e+00  7.40825545e-01  5.52503718e-01 ...  2.27720450e-14\n",
      "  -9.07313667e-15 -2.73819417e-01]\n",
      " [ 1.00000000e+00 -1.00190088e-12  3.19514914e+00 ...  2.27720450e-14\n",
      "  -9.07313667e-15 -2.93969258e-01]\n",
      " ...\n",
      " [ 1.00000000e+00 -3.10930051e-01  3.19315808e-01 ...  2.27720450e-14\n",
      "  -9.07313667e-15 -3.17016595e-01]\n",
      " [ 1.00000000e+00 -5.10096314e-01 -8.45322280e-01 ...  2.27720450e-14\n",
      "  -9.07313667e-15 -7.45437922e-01]\n",
      " [ 1.00000000e+00 -1.00190088e-12  6.65334753e-01 ...  2.27720450e-14\n",
      "  -9.07313667e-15 -7.45437922e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(tx_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8 # 100ratio% of the data will be used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = split_data(tx, y, ratio, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_log, y_train_log, x_test_log, y_test_log = split_data(tx, y_log, ratio, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_log_norm, y_train_log_norm, x_test_log_norm, y_test_log_norm = split_data(tx_normalized, y_log, ratio, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_log_stand, y_train_log_stand, x_test_log_stand, y_test_log_stand = split_data(tx_standardized, y_log, ratio, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy train :  0.74526  || f1_score train:  0.29218932789111\n",
      "Categorical accuracy test :  0.7438212040092137  || f1_score test:  0.2880090136041475\n"
     ]
    }
   ],
   "source": [
    "weights_LS = least_squares(y_train, x_train)[1]\n",
    "cat_accuracy_train, f1_score_train = metrics(weights_LS,y_train,x_train)\n",
    "cat_accuracy_test, f1_score_test = metrics(weights_LS,y_test,x_test)\n",
    "\n",
    "\n",
    "print(\"Categorical accuracy train : \",cat_accuracy_train,\" || f1_score train: \",f1_score_train)\n",
    "print(\"Categorical accuracy test : \",cat_accuracy_test,\" || f1_score test: \",f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy train :  0.66599  || f1_score train:  0.02449624654286843\n",
      "Categorical accuracy test :  0.6669453313293193  || f1_score test:  0.023779812643900382\n"
     ]
    }
   ],
   "source": [
    "weights_LSGD1 = least_squares_GD(y_train, x_train, np.zeros(31), 100, 0.000001)[1]\n",
    "cat_accuracy_train, f1_score_train = metrics(weights_LSGD1,y_train,x_train)\n",
    "cat_accuracy_test, f1_score_test = metrics(weights_LSGD1,y_test,x_test)\n",
    "\n",
    "\n",
    "print(\"Categorical accuracy train : \",cat_accuracy_train,\" || f1_score train: \",f1_score_train)\n",
    "print(\"Categorical accuracy test : \",cat_accuracy_test,\" || f1_score test: \",f1_score_test)\n",
    "\n",
    "# THIS CONVERGES INTO A LOCAL MINIMUM, solution: Dynamic Step Size ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy train :  0.74516  || f1_score train:  0.2916860631478247\n",
      "Categorical accuracy test :  0.7437055878193898  || f1_score test:  0.28759185227489054\n"
     ]
    }
   ],
   "source": [
    "weights_LSGD2 = least_squares_GD(y, tx, [-1.15430619e+00,  1.82637143e-04, -7.20672107e-03, -6.45384640e-03,\n",
    "        -1.73123839e-05,  2.32665195e-02,  4.20381986e-04,  2.50304362e-03,\n",
    "         3.60203545e-01, -1.26385429e-03, -2.84568774e+00, -2.22719927e-01,\n",
    "         9.89163555e-02,  3.56752661e-01,  2.85396180e+00, -6.42020723e-04,\n",
    "        -4.57219107e-04,  2.85879539e+00, -6.80776737e-04,  1.38605239e-03,\n",
    "         3.15125355e-03,  5.15272243e-04, -3.71558734e-04,  4.27220740e-02,\n",
    "        -1.01225645e-03,  4.70620275e-04,  1.34341503e-04, -2.12423006e-03,\n",
    "         1.42389540e-03, -1.78105047e-03,  2.84577828e+00], 100, 0.000001)[1]\n",
    "\n",
    "cat_accuracy_train, f1_score_train = metrics(weights_LSGD2,y_train,x_train)\n",
    "cat_accuracy_test, f1_score_test = metrics(weights_LSGD2,y_test,x_test)\n",
    "\n",
    "\n",
    "print(\"Categorical accuracy train : \",cat_accuracy_train,\" || f1_score train: \",f1_score_train)\n",
    "print(\"Categorical accuracy test : \",cat_accuracy_test,\" || f1_score test: \",f1_score_test)\n",
    "\n",
    "# IT STAYS IN THE ABSOLUTE MINIMUM WHEN USING THAT AS A STARTING POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy train :  0.70589  || f1_score train:  0.345651337747687\n",
      "Categorical accuracy test :  0.7052498643733158  || f1_score train:  0.3426659493400349\n"
     ]
    }
   ],
   "source": [
    "weights_LSSGD = least_squares_SGD(y, tx, np.zeros(31), 10, 0.000001)[1]\n",
    "\n",
    "cat_accuracy_train, f1_score_train = metrics(weights_LSSGD,y_train,x_train)\n",
    "cat_accuracy_test, f1_score_test = metrics(weights_LSSGD,y_test,x_test)\n",
    "\n",
    "\n",
    "print(\"Categorical accuracy train : \",cat_accuracy_train,\" || f1_score train: \",f1_score_train)\n",
    "print(\"Categorical accuracy test : \",cat_accuracy_test,\" || f1_score train: \",f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7438212040092137 0.2880090136041475\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.005\n",
    "\n",
    "weights_RR = ridge_regression(y_train, x_train, lambda_)[1]\n",
    "cat_acc_test, f1_score_test = metrics(weights_RR, y_test, x_test)\n",
    "\n",
    "print(cat_acc_test, f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logistic_regression() missing 2 required positional arguments: 'lr' and 'num_iterations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-ae99438546d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'implementations.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mweights_log_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: logistic_regression() missing 2 required positional arguments: 'lr' and 'num_iterations'"
     ]
    }
   ],
   "source": [
    "num_iterations = 10000\n",
    "lr = 0.005\n",
    "w = np.zeros(31)\n",
    "%run implementations.py\n",
    "weights_log_reg = logistic_regression(x_train_log, y_train_log, w, lr, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigmoid_activation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-da1c93922b23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'implementations.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mweights_log_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_log_stand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test_log_stand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ML1\\ML\\implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[1;34m(tx, y, tx_test, y_test, ws, lr, num_iterations)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost_log_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_labels_log_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m             \u001b[0macc_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_labels_log_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             print(\"Step: \", iteration, \" loss: \", loss,\n",
      "\u001b[1;32m~\\Desktop\\ML1\\ML\\implementations.py\u001b[0m in \u001b[0;36mmetrics\u001b[1;34m(weights, y_test, x_test, predict)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML1\\ML\\proj1_helpers.py\u001b[0m in \u001b[0;36mpredict_labels_log_reg\u001b[1;34m(weights, data)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_labels_log_reg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;34m\"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sigmoid_activation' is not defined"
     ]
    }
   ],
   "source": [
    "num_iterations = 100000\n",
    "lr = 0.005\n",
    "w = np.zeros(31)\n",
    "%run implementations.py\n",
    "weights_log_reg = logistic_regression(x_train_log_stand, y_train, x_test_log_stand, y_test, w, lr, num_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tX_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-537e9d75b8b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tX_test' is not defined"
     ]
    }
   ],
   "source": [
    "tX_test = np.insert(tX_test, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "time_day = datetime.datetime.now().day\n",
    "time_hour = datetime.datetime.now().hour\n",
    "time_min = datetime.datetime.now().minute\n",
    "time_second = datetime.datetime.now().second\n",
    "\n",
    "time = str(time_day)+\"-\"+str(time_hour)+\"-\"+str(time_min)+\"-\"+str(time_second)\n",
    "\n",
    "OUTPUT_PATH = 'submission'+\"_\"+str(time)+\".csv\"\n",
    "print(weights_LS.shape)\n",
    "y_pred = predict_labels(weights_LS, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
